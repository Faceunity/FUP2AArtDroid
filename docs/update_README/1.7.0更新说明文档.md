# 1.7.0 更新文档

## 资源更新

#### 资源更新：

如果项目中有用到Demo中的资源（不管是jar、aar、assets文件夹下的资源、so库），最好全部更新一遍！最好全部更新一遍！最好全部更新一遍！（重要的事情说三遍）

```C
1.libs中的库文件更新，其中p2a_client.jar替换之前的FUPTAClient.jar，新增FUTtsEngine.aar语音驱动库

2.assets文件下的资源更新；
  hair_mask.bundle:头发遮罩应用于ar模式；
  human3d.bundle:身体驱动道具；
  plane_mg.bundle：平地阴影道具，应用于不跟随模式的身体驱动；  
  net_config.json:配置服务器地址，不在Constant类直接定义；
  pta_api2.pem和pta_ptoa.pem：https ca鉴权证书；
  new文件下的facepup.json：捏脸点位，不再EditFaceParameter中直接定义，方便后续维护；
  sta_bs_blend_weight.json：语音驱动定义声明，应用于语音驱动模式

3.jniLibs文件下的资源更新；新增libfuai.so:处理身体驱动接口的库；libp2a_client.so替换libFUP2AClient.so
```
#### 新增JSON配置表

在V1.6.0版本中，我们的assets资源路径都是配置在Java文件中。在V1.7.0版本中，我们已经将对应的资源文件路径都配置到了对应的JSON表中。

------

## 方法名更换

`fuAvatarToTexture` 更换为 `fuRenderBundles` 

`fuDualInputToTexture` 方法更改为 `fuRenderBundlesWithCamera` 

## 新增接口

```C
1.buffer数据旋转接口： 
//RotatedImage接口新定义的结构体：包含byte数组和对应的宽高，接口处理后会把新的buffer数据存储在结构体mData里面
//buffer：需要处理的数据源（如相机数据）
//bufferrType：数据源的类型（如NV21类型）
//rotateMode：需要数据旋转的角度（faceunity.FU_ROTATION_MODE_0，faceunity.FU_ROTATION_MODE_90，faceunity.FU_ROTATION_MODE_180，faceunity.FU_ROTATION_MODE_270）
//flipX和flipY：左右镜像和上下镜像
faceunity.fuRotateImage(faceunity.RotatedImage RotatedImage, byte[] buffer, int bufferrType, int bufferWidth, int bufferHeight, int rotateMode, int flipX, int flipY)  

2.fuRenderBundles：
//AvatarInfo:封装了之前的rotation，expression，pupil_pos，rotation_mode，和isTracking（是否有人脸）
faceunity.fuRenderBundles(faceunity.AvatarInfo AvatarInfo, int flags, int width, int height, int mFrameId, int[] itemsArray);  
  
```
------
## 代码改动

+ 1.新的版本增加了绑定 `controller_congig.bundle` 的形式进行绑定配置，具体的代码可以参考 `PTACore` 

  ```java
  public PTACore(Context context, FUPTARenderer fuP2ARenderer) {
          super(context, fuP2ARenderer);
  
          configItem = mFUItemHandler.loadFUItem(FilePathFactory.BUNDLE_controller_config);
          bgItem = mFUItemHandler.loadFUItem(FilePathFactory.BUNDLE_default_bg);
          bgItems[0] = bgItem;
          mItemsArray[ITEM_ARRAYS_FXAA] = fxaaItem = mFUItemHandler.loadFUItem(FilePathFactory.BUNDLE_fxaa);
      }
  ```

+ 2.BaseCore中   

  ```java
  float[] expressionData = new float[56];
          float[] rotationData = new float[4];
          float[] pupilPosData = new float[2];
          float[] rotationModeData = new float[1];
  使用faceunity.AvatarInfo进行替换
          avatarInfo.mExpression = new float[57];
          avatarInfo.mRotation = new float[4];
          avatarInfo.mPupilPos = new float[2];
          avatarInfo.mRotationMode = new float[1];
  ```

+ 3.新增FUPTAClient类，PTAClientWrapper类中的FUP2AClient类替换为新增的FUPTAClient类

+ 4.PTACore的onDrawFrame绘制方法修改为：

  ```java
  faceunity.fuAvatarToTexture(avatarInfo,0, w, h, mFrameId++, itemsArray())
  ```

+ 5.人脸数据填充修改为：

  ```java
  //是否开启人脸驱动
  if (isNeedTrackFace && img != null) {
      faceunity.fuTrackFaceWithTongue(img, 0, w, h);
      isTracking = faceunity.fuIsTracking();
      if (isTracking > 0) {
          /**
           * rotation 人脸三维旋转，返回值为旋转四元数，长度4
           */
          faceunity.fuGetFaceInfo(0, "rotation_aligned", avatarInfo.mRotation);
          /**
           * expression  表情系数，长度57
           */
          faceunity.fuGetFaceInfo(0, "expression_aligned", avatarInfo.mExpression);
          /**
           * pupil pos 眼球方向，长度2
           */
          faceunity.fuGetFaceInfo(0, "pupil_pos", avatarInfo.mPupilPos);
          /**
           * rotation mode 人脸朝向，0-3分别对应手机四种朝向，长度1
           */
          faceunity.fuGetFaceInfo(0, "rotation_mode", avatarInfo.mRotationMode);
      }
  }
  if (isTracking <= 0) {
      Arrays.fill(avatarInfo.mRotation, 0.0f);
      Arrays.fill(avatarInfo.mExpression, 0.0f);
      Arrays.fill(avatarInfo.mPupilPos, 0.0f);
      Arrays.fill(avatarInfo.mRotationMode, 0.0f);
  }
  avatarInfo.mIsValid = isTracking > 0 ? true : false;
  avatarInfo.mRotationMode[0] = 0;
  ```

+ 6.绘制逻辑修改，预先对纹理和buffer进行转正处理（即：把两者处理成竖直方向），
  具体逻辑参考CameraRender：

  ```java
  rotateMode = mCurrentCameraType == Camera.CameraInfo.CAMERA_FACING_FRONT ? faceunity.FU_ROTATION_MODE_270 : faceunity.FU_ROTATION_MODE_90;
                  flipX = mCurrentCameraType == Camera.CameraInfo.CAMERA_FACING_FRONT ? 1 : 0;
                  flipY = 0;
                  //faceunity.fuSetOutputResolution(1080, 1920);//设置输出纹理的宽高
                  faceunity.fuRotateImage(mRotatedImage, mCameraNV21Byte, NVFormat, mCameraWidth, mCameraHeight, rotateMode, flipX, flipY);
                  //设置texture的绘制矩阵
                  faceunity.fuSetInputCameraMatrix(flipX, flipY, rotateMode);
                  mFuTextureId = mOnCameraRendererStatusListener.onDrawFrame(mRotatedImage.mData, mCameraTextureId, mRotatedImage.mWidth, mRotatedImage.mHeight, -1);
  
  最后绘制到屏幕上：
  private void drawToScreen() {
        if (mFuTextureId > 0) {
            //纹理矩阵传单位阵接口，因为已经预先把纹理和buffer旋转成竖直的
            mFullFrameRectTexture2D.drawFrame(mFuTextureId, GlUtil.IDENTITY_MATRIX, mvp);
        } else {
            mFullFrameRectTextureOES.drawFrame(mCameraTextureId, mtx, mvp);
        }
    }
  
  拍照逻辑跟绘制一样都是传单位阵
   checkPic(mFuTextureId, GlUtil.IDENTITY_MATRIX, mRotatedImage.mWidth, mRotatedImage.mHeight);
  ```

+ 7.EditFaceParameter的捏脸点位修改为读取json：

  ```java
  JsonUtils jsonUtils = new JsonUtils();
  if (Constant.style == Constant.style_art) {
      jsons = jsonUtils.readFacePupJson("art/facepup.json");
  } else {
      jsons = jsonUtils.readFacePupJson("new/facepup.json");
  }
  HeadBone_stretch = jsons[0];
  HeadBone_shrink = jsons[1];
  HeadBone_wide = jsons[2];
  HeadBone_narrow = jsons[3];
  Head_wide = jsons[4];
  Head_narrow = jsons[5];
  head_shrink = jsons[6];
  head_stretch = jsons[7];
  for (String s : jsons) {
      mMap.put(s, 0F);
  }
  
  所有获取value值的方法：
  public float getValue(Object v) {
  if (v == null || ((Float) v).isNaN() || (float) v < 0) {
      return 0.0f;
  } else {
      return (float) v;
  }
  }
  ```

+ 8.动画逻辑修改，设置当前角色id，然后对当前id进行绑定动画；设置多人动画时必须保证同时播放，否则会不同步：

  ```java
  /**
       * 同步播放动画
       *
       * @param avatar
       * @param roleId
       */
      private void syncPlayAnim(AvatarPTA avatar, int roleId) {
          for (int i = 0; i < mAvatarP2As.length; i++) {
              if (mAvatarP2As[i] == null && (Constant.style == Constant.style_new || (Constant.style == Constant.style_art && avatar.getGender() == mScenes.bundles[i].gender))) {
                  avatar.setExpression(mScenes.bundles[i]);
                  final AvatarHandle avatarHandle = mAvatarHandleSparse.get(roleId);
                  mP2AMultipleCore.setCurrentInstancceId(roleId);
                  avatarHandle.setAvatar(mAvatarP2As[i] = avatar, new Runnable() {
                      @Override
                      public void run() {
                          mAvatarLayout.setIsLoadEnd(2);
                          mAvatarLayout.updateAvatarPoint();
                          if (++isLoadComplete == mAvatarHandleSparse.size()) {
                              if (isAnimationScenes) {
                                  //startGifEncoder();
                                  mActivity.runOnUiThread(new Runnable() {
                                      @Override
                                      public void run() {
                                          mCurrentAvatarHandler = avatarHandle;
                                          startRecording();
                                      }
                                  });
                              } else {
                                  mAvatarLayout.updateNextBtn(true);
                              }
                          }
                          if (isAnimationScenes) {
                              Map<Integer, Integer> usedRole = mAvatarLayout.getUsedRoleId();
                              boolean[] isSels = mAvatarLayout.getIsSelectList();
                              for (int j = 0; j < isSels.length; j++) {
                                  if (isSels[j]) {
                                      int f_roleId = usedRole.get(j);
                                      if (f_roleId != roleId) {
                                          mAvatarHandleSparse.get(usedRole.get(j)).setAnimState(3, usedRole.get(j));
                                          mAvatarHandleSparse.get(usedRole.get(j)).seekToAnimBegin(mAvatarHandleSparse.get(usedRole.get(j)).expressionItem.handle);
                                          if (mAvatarHandleSparse.get(usedRole.get(j)).otherItem[1] != null) {
                                              mAvatarHandleSparse.get(usedRole.get(j)).seekToAnimBegin(mAvatarHandleSparse.get(usedRole.get(j)).otherItem[1].handle);
                                          }
                                      }
                                  }
                              }
                              mAvatarHandleSparse.get(roleId).setAnimState(3, roleId);
                              mAvatarHandleSparse.get(roleId).seekToAnimBegin(mAvatarHandleSparse.get(roleId).expressionItem.handle);
                              if (mAvatarHandleSparse.get(roleId).otherItem[1] != null) {
                                  /**
                                   *  道具动画逻辑修改
                                   *  需要加载道具模型和道具动画（图形自动寻找对应的动画）
                                   *  需要和人物动画一起开始（保持同步）
                                   *  注意：配置json信息的时候，需要将道具动画放在第二个位置
                                   */
                                  mAvatarHandleSparse.get(roleId).seekToAnimBegin(mAvatarHandleSparse.get(roleId).otherItem[1].handle);
                              }
                          }
                      }
                  });
                  break;
              }
          }
      }
  ```

+ 9.nama库进行了优化更新，当itemsArray数组为空的时候，需要调用fuTrackFace方法，否则识别不到人脸。改动类为NamaCore.java，代码更改为：

  ```java
  @Override
  public int onDrawFrame(byte[] img, int tex, int w, int h, int rotation) {
      if (img == null) return 0;
      int fuTex = faceunity.fuRenderBundlesWithCamera(img, tex, faceunity.FU_ADM_FLAG_EXTERNAL_OES_TEXTURE, w, h, mFrameId++, itemsArray());
      faceunity.fuTrackFace(img, 0, w, h);
      return fuTex;
  }
  ```

+ 10.nama库进行了优化更新，当itemsArray数组为空的时候，需要调用fuTrackFace方法，否则识别不到人脸。改动类为PTAARCore.java

  ```java
  @Override
  public int onDrawFrame(byte[] img, int tex, int w, int h, int rotation) {
    if (img == null) return 0;
    int flags = 1;
    int isTracking = 0;
    //是否开启面部追踪
    if (isNeedTrackFace && img != null) {
        //trackface
        faceunity.fuTrackFaceWithTongue(img, 0, w, h);
        isTracking = faceunity.fuIsTracking();
        if (isTracking > 0) {
            /**
             * rotation 人脸三维旋转，返回值为旋转四元数，长度4
             */
            faceunity.fuGetFaceInfo(0, "rotation_aligned", avatarInfo.mRotation);
            /**
             * expression  表情系数，长度57
             */
            faceunity.fuGetFaceInfo(0, "expression_aligned", avatarInfo.mExpression);
            /**
             * pupil pos 眼球方向，长度2
             */
            faceunity.fuGetFaceInfo(0, "pupil_pos", avatarInfo.mPupilPos);
            /**
             * rotation mode 人脸朝向，0-3分别对应手机四种朝向，长度1
             */
            faceunity.fuGetFaceInfo(0, "rotation_mode", avatarInfo.mRotationMode);
        }
    }
    if (isTracking <= 0) {
        Arrays.fill(avatarInfo.mRotation, 0.0f);
        Arrays.fill(avatarInfo.mExpression, 0.0f);
        Arrays.fill(avatarInfo.mPupilPos, 0.0f);
        Arrays.fill(avatarInfo.mRotationMode, 0.0f);
    }
    if (rotation < 0) {
        avatarInfo.mRotationMode[0] = 0;
    } else {
        avatarInfo.mRotationMode[0] = 0;
    }
    avatarInfo.mIsValid = isTracking > 0 ? true : false;
  
    if (mode == BodyDriveFragment.TYPE_TEXT_DRIVE) {
        //文字驱动模式
        if (isPlaying) {
            if ((int) (changeRate * currentFrameId) >= mExpressions.size()) {
                Arrays.fill(expressions, 0.0f);
                faceunity.fuItemSetParam(avatarARHandle.controllerItem, "blend_expression", expressions);
                if ((int) (changeRate * (currentFrameId - 2)) >= mExpressions.size()) {
                    stopPlay();
                }
            } else {
                // 拷贝一次数组，不污染原有数据
                for (int i = 0; i < expressions.length; i++) {
                    expressions[i] = mExpressions.get((int) (changeRate * currentFrameId))[i];
                }
                faceunity.fuItemSetParam(avatarARHandle.controllerItem, "blend_expression", expressions);
            }
            currentFrameId++;
        }
        int fuTex = faceunity.fuRenderBundles(avatarInfo,
                0, w, h, mFrameId++, itemsArray());
        if (renderNum < 0)
            return 0;
        renderNum++;
        if (renderNum <= 3) {
            return 0;
        }
        return fuTex;
    } else if (mode == BodyDriveFragment.TYPE_AR_DRIVE) {
        //AR模式
        int fuTex = faceunity.fuRenderBundlesWithCamera(img, tex, flags, w, h, mFrameId++, itemsArray());
        faceunity.fuTrackFace(img, 0, w, h);
        return fuTex;
    }
    return 0;
  }
  ```

+ 11.在生成形象的过程中，我们通过上传头像后获取到的返回数据格式有变化，改动类为`TakePhotoFragment.java` 

  ```java
  String token = jsonObject.optString("token");
  Object latest = jsonObject.opt("latest");
  Object type = jsonObject.opt("type");
  if (latest != null && type != null) {
      Log.i(TAG, "latest=" + latest + "--type=" + type);
      if (!((String) latest).equals(Constant.pta_client_version_new)) {
          if (mCreateAvatarDialog != null)
              mCreateAvatarDialog.dismiss();
          FileUtil.deleteDirAndFile(dir);
          mActivity.runOnUiThread(new Runnable() {
              @Override
              public void run() {
                  new AlertDialog.Builder(mActivity)
                          .setTitle("警告")
                          .setCancelable(false)
                          .setMessage("当前版本与服务器版本不一致，无法生成")
                          .setNegativeButton("确定", new DialogInterface.OnClickListener() {
                              @Override
                              public void onClick(DialogInterface dialog, int which) {
                                  dialog.dismiss();
                              }
                          })
                          .show();
              }
          });
          return;
      }
  }
  ```

+ 12.新版本中为了凸显不同性别的特征，在切换衣服的同时也可能需要切换模型的身体。改动类为 `EditFaceFragment.java` :

  ```java
  if (pos_cloth_upper != 0) {
      if (mAvatarP2A.getClothesUpperFile().contains("female.bundle")) {
          mAvatarP2A.setGender(AvatarPTA.gender_girl);
      } else {
          mAvatarP2A.setGender(AvatarPTA.gender_boy);
      }
  }
  ```

+ 13.在 `EditFaceFragment` 中我们丰富了对人物模型的塑造，我们添加了**上衣**、**下衣**和**配饰**。

+ 14.由于底层库调整了图像的方法，所以客户端在捏脸点位的时候也需要作出相应的调整。

  ```java
  private void parsePoint(EditFacePoint[] editFacePoints, int width, int height, int widthView, int heightView) {
      for (EditFacePoint point : editFacePoints) {
          Point p = mAvatarHandle.getPointByIndex(point.index);
  
          int x = p.x;
          int y = p.y;
          y = height - y;
  
          float sW = (float) widthView / width;
          float sH = (float) heightView / height;
          if (sW > sH) {
              x = (int) (x * sW);
              y = (int) (y * sW + (heightView - height * sW) / 2);
          } else {
              x = (int) (x * sH + (widthView - width * sH) / 2);
              y = (int) (y * sH);
          }
  
          point.set(x, y);
      }
  }
  ```

  

## 注意

```C
所有经过预处理的返回的buffer数据和纹理数据都是竖直的，所以涉及它们相关的处理需要按照竖直来，不能按照之前的处理，比如绘制和拍照
```

<font color="#ff0000">如果项目中有用到Demo中的类，也请一并更新，确保能够正常的运行。</font>