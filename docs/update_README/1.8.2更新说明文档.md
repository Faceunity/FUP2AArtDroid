# 1.8.2更新说明文档

**说明：本文档适用于PTA 1.8.1版本的更新升级，如果您项目中的版本过低，请按照之前的升级文档一步一步进行升级操作。**

## 本次升级所带来的优化内容

<a href="###1、优化渲染性能，将nama.so更新为cnama.so" >1、优化渲染性能，将nama.so更新为cnama.so</a>

<a href="###2、优化驱动算法模型" >2、优化驱动算法模型</a>

<a href="###3、优化合影录制出现的黑屏问题" >3、优化合影录制出现的黑屏问题</a>

<a href="###4、替换接口域名，无需在本地内置https证书" >4、替换接口域名，无需在本地内置https证书</a>

### 1、优化渲染性能，将nama.so更新为cnama.so

**更新库**

+ nama.jar
+ libfuai.so
+ 去掉libnama.so，新增libCNamaSDK.so

**更新资源**

+ assets/new/controller.bundle更名为controller_cpp.bundle 并更新
+ assets/new/controller_config.bundle
+ assets/fxaa.bundle
+ assets/new/body/所有资源
+ assets/new/gesture/所有资源
+ assets/new/color.json

**代码改动**

```java
[FUPTARenderer.java]

/**
 * 创建及初始化faceunity相应的资源
 */
public void onSurfaceCreated() {
//        faceunity.fuSetExpressionCalibration(2);
//        faceunity.fuSetMaxFaces(1);//设置多脸，目前最多支持8人。
//        faceunity.fuSetAsyncTrackFace(0);
}

// 优化空error的打印
public void prepareDrawFrame(){
    ...
    if (error != 0 && !TextUtils.isEmpty(faceunity.fuGetSystemErrorString(error))) {
        Log.e(TAG, "fuGetSystemErrorString " + faceunity.fuGetSystemErrorString(error));
    }
  	...
}
```

### 2、优化驱动算法模型

#### **更新资源**

+ `assets/face_processor_capture.bundle` 改名为 `assets/ai_face_processor.bundle` 并更新
+ `assets/human_3d.bundle` 改名为 `assets/ai_human_processor.bundle` 并更新

#### **更新代码**

```java
[FilePathFactory.java]

public static final String BUNDLE_ai_face_processor = "ai_face_processor.bundle";
public static final String BUNDLE_ai_human_processor = "ai_human_processor.bundle";
```

**`FUPTARenderer` 中添加加载面驱跟身体驱动的方法**

```java
[FUPTARenderer.java]

// 提前加载算法数据模型，用于人脸检测
loadAiModel(context, FilePathFactory.BUNDLE_ai_face_processor, faceunity.FUAITYPE_FACEPROCESSOR);


/**
 * 加载 AI 模型资源
 *
 * @param context
 * @param bundlePath ai_model.bundle
 * @param type       faceunity.FUAITYPE_XXX
 */
private static void loadAiModel(Context context, String bundlePath, int type) {
    byte[] buffer = readFile(context, bundlePath);
    if (buffer != null) {
        int isLoaded = faceunity.fuLoadAIModelFromPackage(buffer, type);
        Log.d(TAG, "loadAiModel. type: " + type + ", isLoaded: " + (isLoaded == 1 ? "yes" : "no"));
    }
}

/**
 * 释放 AI 模型资源
 *
 * @param type
 */
private static void releaseAiModel(int type) {
    if (faceunity.fuIsAIModelLoaded(type) == 1) {
        int isReleased = faceunity.fuReleaseAIModel(type);
        Log.d(TAG, "releaseAiModel. type: " + type + ", isReleased: " + (isReleased == 1 ? "yes" : "no"));
    }
}

/**
 * 从 assets 文件夹或者本地磁盘读文件
 *
 * @param context
 * @param path
 * @return
 */
private static byte[] readFile(Context context, String path) {
    InputStream is = null;
    try {
        is = context.getAssets().open(path);
    } catch (IOException e1) {
        Log.w(TAG, "readFile: e1", e1);
        // open assets failed, then try sdcard
        try {
            is = new FileInputStream(path);
        } catch (IOException e2) {
            Log.w(TAG, "readFile: e2", e2);
        }
    }
    if (is != null) {
        try {
            byte[] buffer = new byte[is.available()];
            int length = is.read(buffer);
            Log.v(TAG, "readFile. path: " + path + ", length: " + length + " Byte");
            is.close();
            return buffer;
        } catch (IOException e3) {
            Log.e(TAG, "readFile: e3", e3);
        }
    }
    return null;
}

public void createHuman3d(Context context) {
    loadAiModel(context, FilePathFactory.BUNDLE_ai_human_processor, faceunity.FUAITYPE_HUMAN_PROCESSOR);
}

/**
 * 每帧处理画面时被调用
 */
private void prepareDrawFrame() {
    //计算FPS等数据
    benchmarkFPS();

    //获取人脸是否识别，并调用回调接口
    int isTracking = mFUCore.isTracking();
    if (mOnTrackingStatusChangedListener != null && mTrackingStatus != isTracking) {
        mOnTrackingStatusChangedListener.onTrackingStatusChanged(mTrackingStatus = isTracking);
    }

    //获取faceunity错误信息，并调用回调接口
    int error = faceunity.fuGetSystemError();
    if (error != 0 && !TextUtils.isEmpty(faceunity.fuGetSystemErrorString(error))) {
        Log.e(TAG, "fuGetSystemErrorString " + faceunity.fuGetSystemErrorString(error));
    }
    if (mOnSystemErrorListener != null && error != 0) {
        mOnSystemErrorListener.onSystemError(error == 0 ? "" : faceunity.fuGetSystemErrorString(error));
    }

    //获取是否正在表情校准，并调用回调接口
    final float[] isCalibratingTmp = new float[1];
    faceunity.fuGetFaceInfo(0, "is_calibrating", isCalibratingTmp);
    if (mOnCalibratingListener != null && isCalibratingTmp[0] != mIsCalibrating) {
        mOnCalibratingListener.OnCalibrating(mIsCalibrating = isCalibratingTmp[0]);
    }

    //queueEvent的Runnable在此处被调用
    while (mEventQueue != null && !mEventQueue.isEmpty()) {
        Runnable r = mEventQueue.remove(0);
        if (r != null)
            r.run();
    }
    mEventQueue.addAll(mNextEventQueue);
    mNextEventQueue.clear();
}

```

**`BaseCore` 中修改获取人脸信息的相关方法**

```java
[BaseCore.java]
// 删除面驱道具句柄
public long face_capture;

public BaseCore(Context context, FUPTARenderer fuP2ARenderer) {
   	...
    avatarInfo.mPupilPos = new float[2];
    ...
}

// 切换相机的方法修改
public void onCameraChange(final int currentCameraType, final int inputImageOrientation) {
    queueEvent(new Runnable() {
        @Override
        public void run() {
            mCurrentCameraType = currentCameraType;
            mInputImageOrientation = inputImageOrientation;
            faceunity.fuOnCameraChange();
        }
    });
}


public int isTracking() {
        return faceunity.fuIsTracking();

    }

// 关于人脸数据的方法修改
/**
 * landmarks 2D人脸特征点，返回值为75个二维坐标，长度75*2
 */
public float[] getLandmarksData() {
    Arrays.fill(landmarksData, 0.0f);
    faceunity.fuGetFaceInfo(0, "landmarks", landmarksData);
    return landmarksData;
}

/**
 * rotation 人脸三维旋转，返回值为旋转四元数，长度4
 */
public float[] getRotationData() {
    Arrays.fill(avatarInfo.mRotation, 0.0f);
    faceunity.fuGetFaceInfo(0, "rotation", avatarInfo.mRotation);
    return avatarInfo.mRotation;
}

public float[] getFaceRectData() {
    Arrays.fill(faceRectData, 0.0f);
    faceunity.fuGetFaceInfo(0, "face_rect", faceRectData);
    return faceRectData;
}

/**
 * expression  表情系数，长度57
 */
public float[] getExpressionData() {
    Arrays.fill(avatarInfo.mExpression, 0.0f);
    faceunity.fuGetFaceInfo(0, "expression", avatarInfo.mExpression);
    return avatarInfo.mExpression;
}

// 驱动道具销毁方法的修改
/**
 * 销毁面部追踪模型
 *
 * @return
 */
public Runnable destroyAIFaceProcessorModel() {
    return new Runnable() {
        @Override
        public void run() {
            faceunity.fuReleaseAIModel(faceunity.FUAITYPE_FACEPROCESSOR);
        }
    };
}


public Runnable destroyAIHumanProcessorModel() {
    return new Runnable() {
        @Override
        public void run() {
            faceunity.fuReleaseAIModel(faceunity.FUAITYPE_HUMAN_PROCESSOR);
        }
    };
}

```

**`PTAARDriveCore` 中修改相关绘制方法**

```java
[PTAARDriveCore.java]

@Override
public int onDrawFrame(byte[] img, int tex, int w, int h, int rotation) {
    if (img == null) return 0;
    int flags = faceunity.FU_ADM_FLAG_EXTERNAL_OES_TEXTURE;

    int rotationMode = 0;
    MainActivity mainActivity = weakReferenceActivity.get();
    if (mainActivity != null) {
        rotationMode = mainActivity.getSensorOrientation();
        mainActivity.refresh(getLandmarksData());
        if (avatarARHandle != null) {
            avatarARHandle.setScreenOrientation(rotationMode);
        }
        faceunity.fuSetDefaultRotationMode(rotationMode);
    }


    return faceunity.fuRenderBundlesWithCamera(img, tex, flags, w, h, mFrameId++, itemsArray());
}
```

**`PTABodyCore` 中修改身体驱动模型相关方法与绘制相关方法**

```java
[PTABodyCore.java]

public PTABodyCore(Context context, FUPTARenderer fuP2ARenderer) {
    super(context, fuP2ARenderer);
    weakReferenceActivity = new WeakReference<>((MainActivity) context);
    mItemsArray[ITEM_ARRAYS_FXAA] = fxaaItem = mFUItemHandler.loadFUItem(FilePathFactory.BUNDLE_fxaa);
    fuP2ARenderer.createHuman3d(context);
}

@Override
    public int onDrawFrame(byte[] img, int tex, int w, int h, int rotation) {
        if (img == null) return 0;
        if (weakReferenceActivity.get() != null) {
            weakReferenceActivity.get().refreshVideo(getLandmarksData(), w, h);
        }
        if (avatarBodyHandle == null) {
            return fuTex;
        }
        return fuTex = faceunity.fuRenderBundlesWithCamera(img, tex, faceunity.FU_ADM_FLAG_EXTERNAL_OES_TEXTURE, w, h, mFrameId++, itemsArray());
    }

// 销毁身体驱动相关数据
queueEvent(destroyAIHumanProcessorModel());
```

**`PTATextDriveCore` 修改绘制相关方法**

```java
[PTATextDriveCore.java]

//提取到构造方法中
Arrays.fill(avatarInfo.mRotation, 0.0f);
Arrays.fill(avatarInfo.mExpression, 0.0f);
Arrays.fill(avatarInfo.mPupilPos, 0.0f);
Arrays.fill(avatarInfo.mRotationMode, 0.0f);

@Override
public int onDrawFrame(byte[] img, int tex, int w, int h, int rotation) {
    if (img == null) return 0;

    faceunity.fuItemSetParam(mItemsArray[ITEM_ARRAYS_CONTROLLER], "face_detector_status", 0);
    avatarInfo.mRotationMode[0] = 0;
    avatarInfo.mIsValid = false;

    //文字驱动模式
    if (isPlaying && avatarTextDriveHandle != null) {
        if ((int) (changeRate * currentFrameId) >= mExpressions.size()) {
            Arrays.fill(expressions, 0.0f);
            faceunity.fuItemSetParam(avatarTextDriveHandle.controllerItem, "blend_expression", expressions);
            if ((int) (changeRate * (currentFrameId - 2)) >= mExpressions.size()) {
                stopPlay();
            }
        } else {
            // 拷贝一次数组，不污染原有数据
            for (int i = 0; i < expressions.length; i++) {
                expressions[i] = mExpressions.get((int) (changeRate * currentFrameId))[i];
            }
            faceunity.fuItemSetParam(avatarTextDriveHandle.controllerItem, "blend_expression", expressions);
        }
        currentFrameId++;
    }
    return faceunity.fuRenderBundles(avatarInfo,
            0, w, h, mFrameId++, itemsArray());
}
```

**`NamaCore` 修改绘制相关方法**

```java
[NamaCore.java]

private final int controllerItem;

public NamaCore(Context context, FUPTARenderer fuP2ARenderer, int controllerItem) {
    super(context, fuP2ARenderer);
    this.controllerItem = controllerItem;

    setFaceCapture(true);
}

@Override
public int onDrawFrame(byte[] img, int tex, int w, int h, int rotation) {
    if (img == null) return 0;
    //如果道具为空，则不进行图片等识别操作
    return faceunity.fuRenderBundlesWithCamera(img, tex, faceunity.FU_ADM_FLAG_EXTERNAL_OES_TEXTURE, w, h, mFrameId++, itemsArray());
}

@Override
public void release() {
    setFaceCapture(false);
}

public void setFaceCapture(boolean isOpen) {
    mFUP2ARenderer.queueEvent(new Runnable() {
        @Override
        public void run() {
            //3.设置enable_face_processor，说明启用或者关闭面部追踪，value = 1.0表示开启，value = 0.0表示关闭
            faceunity.fuItemSetParam(controllerItem, "enable_face_processor", isOpen ? 1.0 : 0.0);
        }
    });
}
```

**`PTACore` 修改绘制相关方法**

```java
[PTACore.java]

// 提取到构造方法中
Arrays.fill(avatarInfo.mRotation, 0.0f);
Arrays.fill(avatarInfo.mExpression, 0.0f);
Arrays.fill(avatarInfo.mPupilPos, 0.0f);
Arrays.fill(avatarInfo.mRotationMode, 0.0f);

// 将相机与相机之间的过度动画时间设置为0
faceunity.fuItemSetParam(avatarHandle.controllerItem, "camera_animation_transition_time", 0.0);

@Override
public int onDrawFrame(byte[] img, int tex, int w, int h, int rotation) {

int loadCount = avatarHandle.getLoadCount();
if (loadCount != Integer.MAX_VALUE) {
    if (avatarHandle.expressionItem.handle > 0) {
        float progress = avatarHandle.getAnimateProgress(avatarHandle.expressionItem.handle);
        if (loadCount - progress < 0.05 && loadCount - progress > 0) {
            // progress并不是一个整型，我们这里取一个范围，也就是loadCount± 0.05 就算是播放完毕

            if (aniLoadCompletedListener != null && (mFrameId - lastLoadCompletedFrameId > 1)) {
                // (mFrameId - lastLoadCompletedFrameId > 1) 表示上次结束动画在上一帧，这一帧又结束一个新动画，
                // 这显然是不合理的，所以做过滤
                aniLoadCompletedListener.loadCompleted(Math.round(progress), currentHomeAnimationPosition, !canResetHomeAnimationPosition);
                canResetHomeAnimationPosition = true;
                lastLoadCompletedFrameId = mFrameId;
            }
        }
    }
}

if (isNeedTrackFace) {
    return faceunity.fuRenderBundlesWithCamera(img, tex, faceunity.FU_ADM_FLAG_EXTERNAL_OES_TEXTURE, w, h, mFrameId++, itemsArray());
} else {
    return faceunity.fuRenderBundles(avatarInfo,
                                     0, w, h, mFrameId++, itemsArray());
}
}

@Override
public float[] getLandmarksData() {
    Arrays.fill(landmarksData, 0.0f);
    if (isNeedTrackFace && isTracking() > 0)
        faceunity.fuGetFaceInfo(0, "landmarks", landmarksData);
    return landmarksData;
}

// 销毁面驱相关数据
queueEvent(destroyAIFaceProcessorModel());

//删除以下代码
faceunity.fuItemSetParamu64(avatarHandle.controllerItem, "register_face_capture_manager", face_capture);
faceunity.fuItemSetParam(avatarHandle.controllerItem, "register_face_capture_face_id", 0.0);

queueEvent(destroyFaceCaptureItem(face_capture));
```

**`AvatarHandle` 修改开启面部驱动的相关方法**

```java
[AvatarHandle.java]

public void setFaceCapture(boolean isOpen) {
    mBaseCore.queueEvent(new Runnable() {
        @Override
        public void run() {
            //3.设置enable_face_processor，说明启用或者关闭面部追踪，value = 1.0表示开启，value = 0.0表示关闭
            faceunity.fuItemSetParam(controllerItem, "enable_face_processor", isOpen ? 1.0 : 0.0);
        }
    });
}
```

**`AvatarARDriveHandle` 修改开启面部驱动的相关方法**

```java
[AvatarARDriveHandle.java]

public void quitArMode() {
    if (controllerItem > 0)
        mBaseCore.queueEvent(new Runnable() {
            @Override
            public void run() {
                faceunity.fuUnBindItems(controllerItem, new int[]{hairMask});
                faceunity.fuItemSetParam(controllerItem, "quit_ar_mode", 1);
                //3.设置enable_face_processor，说明启用或者关闭面部追踪，value = 1.0表示开启，value = 0.0表示关闭
                faceunity.fuItemSetParam(controllerItem, "enable_face_processor", 0.0);
            }
        });
}

/**
 * 进入ar模式
 */
public void enterArMode() {
    if (controllerItem > 0)
        mBaseCore.queueEvent(new Runnable() {
            @Override
            public void run() {
                faceunity.fuItemSetParam(controllerItem, "enter_ar_mode", 1);
                faceunity.fuBindItems(controllerItem, new int[]{hairMask});
                //3.设置enable_face_processor，说明启用或者关闭面部追踪，value = 1.0表示开启，value = 0.0表示关闭
                faceunity.fuItemSetParam(controllerItem, "enable_face_processor", 1.0);
            }
        });

}
```

**`AvatarBodyHandle` 修改开启面部驱动和身体驱动的相关方法**

```java
[AvatarBodyHandle.java]

/**
 * CNN 面部追踪
 *
 * @param isOpen
 */
public void setCNNTrackFace(boolean isOpen) {
    mBaseCore.queueEvent(new Runnable() {
        @Override
        public void run() {
            //3.设置enable_face_processor，说明启用或者关闭面部追踪，value = 1.0表示开启，value = 0.0表示关闭
            faceunity.fuItemSetParam(controllerItem, "enable_face_processor", isOpen ? 1.0 : 0.0);
        }
    });
}

//开启身体追踪
public void enterBodyDrive() {
    if (controllerItem > 0) {
        mBaseCore.queueEvent(new Runnable() {
            @Override
            public void run() {
                faceunity.fuItemSetParam(controllerItem, "enable_human_processor", 1.0);
            }
        });
    }
}

//退出身体追踪
public void quitBodyDrive() {
    if (controllerItem > 0) {
        mBaseCore.queueEvent(new Runnable() {
            @Override
            public void run() {
                faceunity.fuItemSetParam(controllerItem, "enable_human_processor", 0.0);
            }
        });
    }
}
```

**`CameraRenderer` 修正 `rotation` 参数**

```java
[CameraRenderer.java]
if (offlineNum >= 0 && mIsNeedTakePic) {
    rendWidth = offlineW;
    rendHeight = offlineH;
    mFuTextureId = mOnCameraRendererStatusListener.onDrawFrame(null, 0, rendWidth, rendHeight, 0);
} else {
    mFuTextureId = mOnCameraRendererStatusListener.onDrawFrame(mRotatedImage.mData, mCameraTextureId, rendWidth, rendHeight, 0);
}

```

**`ARFragment` `BodyDriveFragment` `TextDriveFragment` 无需设置面驱道具句柄**

```java
[ARFragment.java]、[BodyDriveFragment.java]、[TakePhotoFragment.java]
// 删除以下代码
mP2AARCore.setFace_capture(mP2ACore.face_capture);
```

**`TakePhotoFragment` 无需设置面驱道具句柄**

```java
[TextDriveFragment.java]

private volatile boolean needTrackFace = true;

mNamaCore = new NamaCore(getContext(), mFUP2ARenderer, mAvatarHandle.controllerItem) {
      @Override
      public int onDrawFrame(byte[] img, int tex, int w, int h, int rotation) {
          //因为已经对双输入的cpu buffer进行旋转、镜像，使其与texture对齐
          //所以这边不需要其他处理
          int fu = super.onDrawFrame(img, tex, w,
                                     h, rotation);
          if (needTrackFace){
              faceunity.fuTrackFace(img, 0, w, h);
          }
          checkPic(w, h);
          return fu;
      }
  };

// createAvatar 方法
needTrackFace = false;

// onPositiveListener 方法
needTrackFace = true;


// 删除以下代码
mP2AARCore.setFace_capture(mP2ACore.face_capture);
```

**`MainActivity` 删除面驱相关代码**

```java
// 删除以下代码
mP2ACore.face_capture = 0;
```

**`FaceCheckUtil` 修改驱动以后会导致之前在拍照界面进行人脸检测的工具类过于灵敏，需要修改数值**

```java
[FaceCheckUtil.java]

public static boolean checkRotation(float[] rotations) {
    double x = rotations[0];
    double y = rotations[1];
    double z = rotations[2];
    double w = rotations[3];
    double yaw = Math.atan2(2 * (w * z + y * z), 1 - 2 * (x * x + y * y)) / Math.PI * 180;
    double pitch = Math.asin(2 * (w * y - z * x)) / Math.PI * 180;
    double roll = Math.atan2(2 * (w * z + x * y), 1 - 2 * (y * y + z * z)) / Math.PI * 180;
    return yaw > 30 || yaw < -30 || pitch > 15 || pitch < -15;
}

public static boolean checkExpression(float[] expressionData) {
    for (float e : expressionData) {
        if (e > 0.8) {
            return true;
        }
    }
    return false;
}
```

### 3、优化合影录制出现的黑屏问题

**`GroupPhotoFragment` 添加录制成功的标志位、优化开始录制时候的动画播放时机**

```java
[GroupPhotoFragment.java]

private boolean recordingStop = false;
private boolean nextEnable = false;

private PTAMultipleCore createPTAMultipleCore() {
    if (mP2AMultipleCore == null) {
        mP2AMultipleCore = new PTAMultipleCore(mActivity, mFUP2ARenderer) {

            @Override
            public int onDrawFrame(byte[] img, int tex, int w, int h, int rotation) {
                int fuTex = super.onDrawFrame(img, tex, w, h, rotation);
                //avatarHandle为空，则生成场景图像
                if (mCurrentAvatarHandler != null) {
                    float nowFrameId = mCurrentAvatarHandler.getAnimateProgress(mCurrentAvatarHandler.expressionItem.handle);
                    if (nowFrameId >= 1.0f) {
                        //录制mp4完成
                        if (!recordingStop) {
                            stopRecording();
                        }
                        enableNext(true);
                    } else {
                        enableNext(false);
                        recordingStop = false;
                        videoUtil.sendRecordingData(fuTex, GlUtil.IDENTITY_MATRIX);
                        GLES20.glFinish();
                    }
                }
                return fuTex;
            }
        };
    } else {
        mP2AMultipleCore.updateBg();
    }
    mP2AMultipleCore.receiveShadowItem(mP2ACore.planeItemLeft, mP2ACore.planeItemRight);
    return mP2AMultipleCore;
}

private void initVideoUtil() {
    videoUtil = new VideoUtil(mActivity.getmGLSurfaceView());
    videoUtil.setRecordCompletedListener(new VideoUtil.RecordStatusListener() {

        @Override
        public void recordStart() {
            resetAnimation(currentRoleId);
        }
    });
}

private void enableNext(boolean enable) {
    if (enable == nextEnable) {
        return;
    }
    nextEnable = enable;
    mActivity.runOnUiThread(new Runnable() {
        @Override
        public void run() {
            mAvatarLayout.updateNextBtn(nextEnable);
        }
    });
}


private void syncPlayAnim(AvatarPTA avatar, int roleId) {
  for (int i = 0; i < mAvatarP2As.length; i++) {
      if (mAvatarP2As[i] == null) {
          avatar.setExpression(mScenes.bundles[i]);
          final AvatarHandle avatarHandle = mAvatarHandleSparse.get(roleId);
          avatarHandle.setNeedNextEventCallback(false);
          mP2AMultipleCore.setCurrentInstancceId(roleId);
          mActivity.setCanClick(false, true);
          avatarHandle.setAvatar(mAvatarP2As[i] = avatar, new Runnable() {
              @Override
              public void run() {
                  if (isAnimationScenes) {
                      mP2AMultipleCore.bindPlane();
                  }
                  mActivity.setCanClick(true, false);
                  mAvatarLayout.updateAvatarPoint();
                  if (++isLoadComplete == mAvatarHandleSparse.size()) {
                      if (isAnimationScenes) {
                          //startGifEncoder();
                          mActivity.runOnUiThread(new Runnable() {
                              @Override
                              public void run() {
                                  mCurrentAvatarHandler = avatarHandle;
                                  startRecording();
                                  enableNext(false);
                              }
                          });
                      } else {
                          enableNext(true);
                      }
                  }
              }
          });
          break;
      }
  }
}

private void resetAnimation(int roleId) {
  if (isAnimationScenes) {
      Map<Integer, Integer> usedRole = mAvatarLayout.getUsedRoleId();
      boolean[] isSels = mAvatarLayout.getIsSelectList();
      for (int j = 0; j < isSels.length; j++) {
          if (isSels[j]) {
              int f_roleId = usedRole.get(j);
              if (f_roleId != roleId) {
                  mAvatarHandleSparse.get(f_roleId).setAnimState(3, f_roleId);
                  mAvatarHandleSparse.get(f_roleId).seekToAnimBegin(mAvatarHandleSparse.get(f_roleId).expressionItem.handle);
                  if (mAvatarHandleSparse.get(f_roleId).otherItem[1] != null) {
                      mAvatarHandleSparse.get(f_roleId).seekToAnimBegin(mAvatarHandleSparse.get(f_roleId).otherItem[1].handle);
                  }
              }
          }
      }
      mAvatarHandleSparse.get(roleId).setAnimState(3, roleId);
      mAvatarHandleSparse.get(roleId).seekToAnimBegin(mAvatarHandleSparse.get(roleId).expressionItem.handle);

      if (mAvatarHandleSparse.get(roleId).otherItem[1] != null) {
          /**
           *  道具动画逻辑修改
           *  需要加载道具模型和道具动画（图形自动寻找对应的动画）
           *  需要和人物动画一起开始（保持同步）
           *  注意：配置json信息的时候，需要将道具动画放在第二个位置
           */
          mAvatarHandleSparse.get(roleId).seekToAnimBegin(mAvatarHandleSparse.get(roleId).otherItem[1].handle);
      }
  }
}

/**
 * 停止录制
 */
private void stopRecording() {
    videoUtil.stopRecording();
    recordingStop = true;
}
```

**`VideoUtil` 添加录制中的标志位和录制成功的回调**

```java
[VideoUtil.java]
/**
 * 录制编码中
 */
private volatile boolean recordingEncoding = false;

// onPrepared 方法
recordingEncoding = true;

// onStopped方法
recordingEncoding = false;

// onError方法
recordingEncoding = false;

// 优化释放mMuxer中的资源
public void startRecording(int width, int height, int cropX, int cropY, int textureWidth,
                           int textureHeight, long interval, String input, MediaEncoder.TimeListener timeListener) {
    try {
        stopRecording();
        String videoFileName = DateUtil.getCurrentDate() + "_tmp.mp4";
        mOutFile = new File(Constant.TmpPath, videoFileName);
        if (!mOutFile.getParentFile().exists()) {
            mOutFile.getParentFile().mkdirs();
        }

        // 如果是在录制中的状态，然后调用setNeedRecord(true) 方法，重新录制，需要等到MediaCodec完全释放资源才能
        // 录制，否则会出现录制失败的问题

        if (recordingEncoding) {

            long l = System.currentTimeMillis();
            while (recordingEncoding) {
                try {
                    Thread.sleep(10);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
            long time = System.currentTimeMillis() - l;
            Log.e(TAG, "startRecording: " + time);
        }

        mMuxer = new MediaMuxerWrapper(mOutFile.getAbsolutePath());

        // for video capturing
        MediaEncoder mediaVideoEncoder;
        mediaVideoEncoder = new MediaVideoEncoder(mMuxer, mMediaEncoderListener, width, height, cropX, cropY,
                textureWidth, textureHeight);
        mediaVideoEncoder.setInterval(interval);

        MediaEncoder mediaEncoder = null;
        if (!TextUtils.isEmpty(input)) {
            mediaEncoder = new MediaAudioEncoder(mMuxer, mMediaEncoderListener);
            mediaEncoder.setInterval(interval);
            //1 * 1000 * 1000 / 25
            maxNum = 2;
        } else {
            maxNum = 1;
        }
        if (mediaEncoder != null) {
            mediaEncoder.setListener(timeListener);
        }
        if (recordCompletedListener != null) {
            recordCompletedListener.recordStart();
        }
        mMuxer.prepare();
        mMuxer.startRecording();
    } catch (final IOException e) {
        Log.e(TAG, "startCapture:", e);
    }
}



private RecordStatusListener recordCompletedListener;

public void setRecordCompletedListener(RecordStatusListener recordCompletedListener) {
    this.recordCompletedListener = recordCompletedListener;
}

public interface RecordStatusListener {

    /**
     * 录制开始了
     */
    void recordStart();
}
```

### 4、替换接口域名，无需在本地内置https证书

#### 资源更新

+ 更新assets/net_config.json
+ 删除pta_ptoa.pem

#### 代码更新

**`OkHttpUtils` 升级Demo中所用到的接口，不在需要本地内置HTTPS证书**

```java
[OkHttpUtils.java]

public static OkHttpClient initOkHttpClient() {
    initNet();
    OkHttpClient.Builder builder = new OkHttpClient.Builder()
            .connectTimeout(60000L, TimeUnit.MILLISECONDS)
            .writeTimeout(60000L, TimeUnit.MILLISECONDS)
            .readTimeout(60000L, TimeUnit.MILLISECONDS);
    return builder.build();
}

// 删除以下代码
public static KeyManagerFactory getKeyManagerFactory(byte[] p12) {
    KeyManagerFactory kmf = null;
    try {
        KeyStore p12KeyStore = KeyStore.getInstance("PKCS12");
        InputStream in = new ByteArrayInputStream(p12);
        p12KeyStore.load(in, "".toCharArray());
        kmf = KeyManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm());
        kmf.init(p12KeyStore, "".toCharArray());
    } catch (Exception e) {
        e.printStackTrace();
    }
    return kmf;
}

static class TrustAllCerts implements X509TrustManager {

    @Override
    public void checkClientTrusted(X509Certificate[] chain, String authType) throws CertificateException {
    }

    @Override
    public void checkServerTrusted(X509Certificate[] chain, String authType) throws CertificateException {
    }

    @Override
    public X509Certificate[] getAcceptedIssuers() {
        return new X509Certificate[0];
    }
}
```

**`FUApplication` 修改初始化的地方**

```java
[FUApplication.java]

OkHttpUtils.initOkHttpUtils(OkHttpUtils.initOkHttpClient());
```

## 本次升级所带来的修复内容

### 1、修复之前dsp加速功能初始化代码缺失的问题

```java
[FUApplication.java]
/**
 * 初始化dsp设备
 * 如果已经调用过一次了，后面再重新初始化bundle，也不需要重新再调用了。
 */
String path = fuApplication.getApplicationInfo().nativeLibraryDir;
faceunity.fuHexagonInitWithPath(path);
```

### 2、合影结果预览界面返回以后，模型不正确的问题

```java
[VideoAndImageActivity.java]
@Override
public void onBackPressed() {
if (isToHome) {
    FuEventBus.getDefault().post(new UpdateHomeAvatarEvent(true));
    new Handler().postDelayed(new Runnable() {
        @Override
        public void run() {
            Intent intent = new Intent(VideoAndImageActivity.this, MainActivity.class);
            startActivity(intent);
            VideoAndImageActivity.super.onBackPressed();
            overridePendingTransition(android.R.anim.fade_in, R.anim.slide_out_bottom);
        }
    }, 500);
} else {
    VideoAndImageActivity.super.onBackPressed();
}
```

## 注意

如果觉得文档描述的比较含糊，可以直接查看github的代码更新记录。